#!/bin/bash
# XSS Vibes V2 - Advanced Crawler Launcher
# Based on Osmedeus architecture with Fofa/Shodan integration

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# XSS Vibes banner
print_banner() {
    echo -e "${PURPLE}"
    cat << "EOF"
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                              â•‘
    â•‘    ğŸ”¥ XSS Vibes V2 - Advanced Endpoint Crawler ğŸ”¥          â•‘
    â•‘                                                              â•‘
    â•‘    ğŸ•·ï¸  Osmedeus-style reconnaissance framework               â•‘
    â•‘    ğŸ¯ Fofa & Shodan integration                              â•‘
    â•‘    âš¡ Async endpoint discovery                               â•‘
    â•‘    ğŸ”¥ Nuclei & Jaeles vulnerability scanning                â•‘
    â•‘                                                              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF
    echo -e "${NC}"
}

# Check dependencies
check_dependencies() {
    echo -e "${YELLOW}ğŸ” Checking dependencies...${NC}"
    
    # Check Python
    if ! command -v python3 &> /dev/null; then
        echo -e "${RED}âŒ Python3 not found${NC}"
        exit 1
    fi
    
    # Check required Python packages
    python3 -c "import aiohttp, requests, yaml" 2>/dev/null || {
        echo -e "${YELLOW}âš ï¸  Installing Python dependencies...${NC}"
        pip3 install -r requirements_crawler.txt
    }
    
    # Check optional tools
    if command -v nuclei &> /dev/null; then
        echo -e "${GREEN}âœ… Nuclei found${NC}"
    else
        echo -e "${YELLOW}âš ï¸  Nuclei not found - vulnerability scanning will be limited${NC}"
    fi
    
    if command -v jaeles &> /dev/null; then
        echo -e "${GREEN}âœ… Jaeles found${NC}"
    else
        echo -e "${YELLOW}âš ï¸  Jaeles not found - advanced scanning unavailable${NC}"
    fi
    
    echo -e "${GREEN}âœ… Dependencies check complete${NC}"
}

# Show usage
show_usage() {
    echo -e "${CYAN}Usage Examples:${NC}"
    echo ""
    echo -e "${GREEN}ğŸ¯ Domain-based reconnaissance:${NC}"
    echo "  $0 -d example.com -w example_scan"
    echo ""
    echo -e "${GREEN}ğŸ” Custom Fofa search:${NC}"
    echo "  $0 -f 'title=\"admin panel\"' -w admin_hunt"
    echo ""
    echo -e "${GREEN}ğŸŒ Shodan search:${NC}"
    echo "  $0 -s 'http.title:login' -w login_hunt"
    echo ""
    echo -e "${GREEN}ğŸ¯ Direct URL targeting:${NC}"
    echo "  $0 -t https://example.com https://test.com -w direct_scan"
    echo ""
    echo -e "${GREEN}ğŸ”¥ Combined reconnaissance:${NC}"
    echo "  $0 -d example.com -f 'domain=\"example.com\"' -s 'hostname:example.com' -w full_scan"
    echo ""
    echo -e "${YELLOW}Options:${NC}"
    echo "  -d  Target domain for reconnaissance"
    echo "  -f  Custom Fofa search query"
    echo "  -s  Custom Shodan search query"
    echo "  -t  Direct target URLs (space-separated)"
    echo "  -w  Workspace name (default: default)"
    echo "  -c  Config file (default: config/crawler_config.yaml)"
    echo "  -h  Show this help"
    echo ""
}

# Setup configuration
setup_config() {
    local config_file="$1"
    
    if [[ ! -f "$config_file" ]]; then
        echo -e "${YELLOW}âš ï¸  Config file not found, creating default...${NC}"
        mkdir -p "$(dirname "$config_file")"
        cp config/crawler_config.yaml "$config_file" 2>/dev/null || {
            echo -e "${RED}âŒ Failed to create config file${NC}"
            exit 1
        }
    fi
    
    echo -e "${GREEN}âœ… Configuration ready: $config_file${NC}"
}

# Run crawler
run_crawler() {
    local domain="$1"
    local fofa_query="$2"
    local shodan_query="$3"
    local targets="$4"
    local workspace="$5"
    local config_file="$6"
    
    echo -e "${CYAN}ğŸš€ Starting Advanced Endpoint Crawler...${NC}"
    echo -e "${BLUE}ğŸ“‚ Workspace: $workspace${NC}"
    
    # Build command
    local cmd="python3 tools/endpoint_hunter.py"
    
    if [[ -n "$domain" ]]; then
        cmd="$cmd -d \"$domain\""
        echo -e "${BLUE}ğŸ¯ Target Domain: $domain${NC}"
    fi
    
    if [[ -n "$fofa_query" ]]; then
        cmd="$cmd -f \"$fofa_query\""
        echo -e "${BLUE}ğŸ” Fofa Query: $fofa_query${NC}"
    fi
    
    if [[ -n "$shodan_query" ]]; then
        cmd="$cmd -s \"$shodan_query\""
        echo -e "${BLUE}ğŸŒ Shodan Query: $shodan_query${NC}"
    fi
    
    if [[ -n "$targets" ]]; then
        cmd="$cmd -t $targets"
        echo -e "${BLUE}ğŸ¯ Direct Targets: $targets${NC}"
    fi
    
    cmd="$cmd -w \"$workspace\""
    
    echo -e "${YELLOW}âš¡ Executing: $cmd${NC}"
    echo ""
    
    # Execute crawler
    eval "$cmd"
    
    # Show results
    local results_dir="workspaces/$workspace"
    if [[ -d "$results_dir" ]]; then
        echo -e "${GREEN}ğŸ‰ Scan completed successfully!${NC}"
        echo -e "${CYAN}ğŸ“Š Results:${NC}"
        
        if [[ -f "$results_dir/reports/summary.json" ]]; then
            python3 -c "
import json
with open('$results_dir/reports/summary.json', 'r') as f:
    data = json.load(f)
    print(f'ğŸ¯ Targets: {data[\"targets_count\"]}')
    print(f'ğŸ•·ï¸ Endpoints: {data[\"endpoints_count\"]}')
    print(f'ğŸ”¥ Vulnerabilities: {data[\"vulnerabilities_count\"]}')
    print(f'ğŸš¨ Critical: {data[\"critical_vulns\"]}')
    print(f'ğŸŸ  High: {data[\"high_vulns\"]}')
    print(f'ğŸŸ¡ Medium: {data[\"medium_vulns\"]}')
    print(f'ğŸ”µ Low: {data[\"low_vulns\"]}')
"
        fi
        
        echo -e "${GREEN}ğŸ“ Workspace: $results_dir${NC}"
        echo -e "${GREEN}ğŸ“Š Report: $results_dir/reports/report.html${NC}"
    else
        echo -e "${RED}âŒ Scan failed or no results generated${NC}"
        exit 1
    fi
}

# Main function
main() {
    print_banner
    
    # Default values
    domain=""
    fofa_query=""
    shodan_query=""
    targets=""
    workspace="default"
    config_file="config/crawler_config.yaml"
    
    # Parse arguments
    while getopts "d:f:s:t:w:c:h" opt; do
        case $opt in
            d) domain="$OPTARG" ;;
            f) fofa_query="$OPTARG" ;;
            s) shodan_query="$OPTARG" ;;
            t) targets="$OPTARG" ;;
            w) workspace="$OPTARG" ;;
            c) config_file="$OPTARG" ;;
            h) show_usage; exit 0 ;;
            *) show_usage; exit 1 ;;
        esac
    done
    
    # Validate arguments
    if [[ -z "$domain" && -z "$fofa_query" && -z "$shodan_query" && -z "$targets" ]]; then
        echo -e "${RED}âŒ Must specify at least one of: -d, -f, -s, or -t${NC}"
        show_usage
        exit 1
    fi
    
    # Setup and run
    check_dependencies
    setup_config "$config_file"
    run_crawler "$domain" "$fofa_query" "$shodan_query" "$targets" "$workspace" "$config_file"
}

# Run main function
main "$@"
